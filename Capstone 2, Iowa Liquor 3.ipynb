{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# ML Predictive Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_f = '/Users/charisameeker/Documents/Data/Iowa Liquor/iowa_liquor_clean2.csv'\n",
    "df1 = pd.read_csv(csv_f,\n",
    "        parse_dates=['date'],\n",
    "        dtype = {'year':np.int16, 'month':np.int8, 'day':np.int8,\n",
    "        'store_number':np.int16, 'county_number':np.int8, 'item_number':np.int32,\n",
    "        'pack':np.int16, 'bottle_vol':np.int64, 'bottle_cost':np.float32,\n",
    "        'state_bottle_retail':np.float32, 'bottles_sold':np.int16, 'sale':np.float32,\n",
    "        'vol_sold':np.float32, 'bottles_sold':np.int16,\n",
    "        'category':np.int32, 'store_subnumber':np.int16, 'zip_code':np.int16,\n",
    "        'vendor_number':np.int16\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'month', 'day', 'store_number', 'city', 'zip_code',\n",
       "       'county_number', 'category', 'vendor_number', 'item_number', 'pack',\n",
       "       'bottle_vol', 'bottle_cost', 'state_bottle_retail', 'bottles_sold',\n",
       "       'sale', 'fd', 'vol_sold', 'store_subnumber'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.drop(['Unnamed: 0', 'date', 'address', 'store_name', 'item_description', 'store_subname', \\\n",
    "        'county', 'category_name', 'vendor_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.zip_code = df1.zip_code.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.city = df1.city.astype('category')\n",
    "df1.zip_code = df1.zip_code.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.city = df1.city.cat.add_categories('NaN')\n",
    "df1.city.fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.query('year == 2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pkl = '/Users/charisameeker/Documents/Data/iowa_liquor_clean4.cats.pkl'\n",
    "df.to_pickle(file_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['fd'].copy().values # fd is the result of applying boxcox on the sale column (fitted data)\n",
    "X = df.copy().drop(['sale', 'fd'], axis=1)\n",
    "X_col = X.copy().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_csv = '/Users/charisameeker/Desktop/iowa_liquor_2016_10k.csv'\n",
    "# df.query('year == 2016').head(10000).to_csv(file_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2279879 entries, 8428101 to 10707979\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Dtype   \n",
      "---  ------               -----   \n",
      " 0   year                 int16   \n",
      " 1   month                int8    \n",
      " 2   day                  int8    \n",
      " 3   store_number         int16   \n",
      " 4   city                 category\n",
      " 5   zip_code             category\n",
      " 6   county_number        int8    \n",
      " 7   category             int32   \n",
      " 8   vendor_number        int16   \n",
      " 9   item_number          int32   \n",
      " 10  pack                 int16   \n",
      " 11  bottle_vol           int64   \n",
      " 12  bottle_cost          float32 \n",
      " 13  state_bottle_retail  float32 \n",
      " 14  bottles_sold         int16   \n",
      " 15  sale                 float32 \n",
      " 16  fd                   float64 \n",
      " 17  vol_sold             float32 \n",
      " 18  store_subnumber      int16   \n",
      "dtypes: category(2), float32(4), float64(1), int16(6), int32(2), int64(1), int8(3)\n",
      "memory usage: 145.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plausible Regressors (without Parameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regression_models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    LinearSVR(),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    xgb.XGBRegressor()\n",
    "]\n",
    "\n",
    "for regression_model in regression_models:\n",
    "    loop_pipe = make_pipeline(regression_model)\n",
    "    loop_pipe.fit(X_train, y_train)   \n",
    "    print(f'{regression_model} \\n\\\n",
    "    model score: {loop_pipe.score(X_test03, y_test03):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestregressor__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'randomforestregressor__max_features': ['auto', 'sqrt'], 'randomforestregressor__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'randomforestregressor__min_samples_split': [2, 5, 10], 'randomforestregressor__min_samples_leaf': [1, 2, 4], 'randomforestregressor__bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# pipeline for categorical features\n",
    "categorical_features = [\"city\", \"zip_code\"]\n",
    "# store_name, item_description, store_subname\n",
    "categorical_transformer = [(\"encoder\", OneHotEncoder(handle_unknown='ignore'))]\n",
    "categorical_transformer = Pipeline(categorical_transformer)\n",
    "\n",
    "#incorporating the random forest estimator\n",
    "pipeline = make_pipeline(categorical_transformer, RandomForestRegressor())\n",
    "\n",
    "# Parameters\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'randomforestregressor__n_estimators': n_estimators,\n",
    "               'randomforestregressor__max_features': max_features,\n",
    "               'randomforestregressor__max_depth': max_depth,\n",
    "               'randomforestregressor__min_samples_split': min_samples_split,\n",
    "               'randomforestregressor__min_samples_leaf': min_samples_leaf,\n",
    "               'randomforestregressor__bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "\n",
    "cv_rf = RandomizedSearchCV(pipeline, random_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best parameters: {cv_rf.best_params_} \\n\\n\\\n",
    "Training accuracy score from tuned model: {cv_rf.best_score_*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = cv_rf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, rf_y_pred)\n",
    "print(f'MSE: {mse:.2f}% \\n\\\n",
    "RMSE: {(mse*(1/2.0)):.2} \\n\\\n",
    "Score: {cv_rf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(24, 12))\n",
    "_ = x_ax = range(len(y_test[-200:]))\n",
    "_ = plt.plot(x_ax, y_test[-200:], label=\"Occurences\")\n",
    "_ = plt.plot(x_ax, rf_y_pred[-200:], label=\"Predictions\")\n",
    "_ = plt.title('Random Forest Regressor for 2016: Occurences Vs. Predictions')\n",
    "_ = plt.xlabel('Last 200 Instances')\n",
    "_ = plt.ylabel('Fitted Sales (2016)')\n",
    "_ = plt.legend()\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for categorical features\n",
    "categorical_features = [\"city\", \"zip_code\"]\n",
    "categorical_transformer = [(\"encoder\", OneHotEncoder(handle_unknown='ignore'))]\n",
    "categorical_transformer = Pipeline(categorical_transformer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### DELETE\n",
    "# divernce of the pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"cat\", categorical_transformer, categorical_features)])\n",
    "### DELETE\n",
    "\n",
    "\n",
    "\n",
    "#incorporating the random forest estimator\n",
    "pipeline = make_pipeline(categorical_transformer, GradientBoostingRegressor())\n",
    "\n",
    "# grid search parameters\n",
    "params = {'gradientboostingregressor__learning_rate': [.1, .3, .5, .7, .9],\n",
    "          'gradientboostingregressor__n_estimators': [50, 80, 100, 120, 140, 180, 250],\n",
    "          'gradientboostingregressor__subsample': [.6, .8, 1, 1.2, 1.4, 1.9],\n",
    "          'gradientboostingregressor__min_samples_split': [1, 2, 3, 4, 6]}\n",
    "\n",
    "cv_gb = RandomizedSearchCV(pipeline, params, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best parameters: {cv_gb.best_params_} \\n\\n\\\n",
    "Training accuracy score from tuned model: {cv_gb.best_score_*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_y_pred = cvcv_gb_rf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, gb_y_pred)\n",
    "print(f'MSE: {mse:.2f}% \\n\\\n",
    "RMSE: {(mse*(1/2.0)):.2} \\n\\\n",
    "Score: {cv_gb.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(24, 12))\n",
    "_ = x_ax = range(len(y_test[-200:]))\n",
    "_ = plt.plot(x_ax, y_test[-200:], label=\"Occurences\")\n",
    "_ = plt.plot(x_ax, gb_y_pred[-200:], label=\"Predictions\")\n",
    "_ = plt.title('Gradient Boosting Regressor for 2016: Occurences Vs. Predictions')\n",
    "_ = plt.xlabel('Last 200 Instances')\n",
    "_ = plt.ylabel('Fitted Sales (2016)')\n",
    "_ = plt.legend()\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'xgbregressor__nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'xgbregressor__objective':['reg:linear'],\n",
    "              'xgbregressor__learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'xgbregressor__max_depth': [5, 6, 7],\n",
    "              'xgbregressor__min_child_weight': [4],\n",
    "              'xgbregressor__silent': [1],\n",
    "              'xgbregressor__subsample': [0.7],\n",
    "              'xgbregressor__colsample_bytree': [0.7],\n",
    "              'xgbregressor__n_estimators': [500]}\n",
    "\n",
    "cv_xgb = RandomizedSearchCV(xgb.XGBRegressor(), parameters, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best parameters: {cv_xgb.best_params_} \\n\\n\\\n",
    "Training accuracy score from tuned model: {cv_xgb.best_score_*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg1 = LinearRegression()\n",
    "lin_reg1.fit(X_train, y_train)\n",
    "y_pred = lin_reg1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg1_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f'Linear Regression Score: {lin_reg1.score(X_test, y_test)} \\n\\n\\\n",
    "Mean Absolute Error: {metrics.mean_absolute_error(y_test, y_pred)} \\n\\n\\\n",
    "RMSE: {lin_reg1_rmse} \\n\\n\\\n",
    "Linear Regression Score: {lin_reg1.score(X_test, y_test)} \\n\\n\\\n",
    "Intercept: {lin_reg1.intercept_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg1_df_y_pred = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "lin_reg1_df_y_pred1 = df_y_pred.sample(25)\n",
    "\n",
    "_ = lin_reg1_df_y_pred1.plot(kind='bar',figsize=(10,8))\n",
    "_ = plt.title('2003: Occurences Vs. Predictions')\n",
    "_ = plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "_ = plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "_ = plt.xlabel('Sample Index Numbers (25 Total)')\n",
    "_ = plt.ylabel('Grade Median Scores')\n",
    "_ = plt.xticks(rotation=80)\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg2 = LinearRegression()\n",
    "\n",
    "# 3-Fold Cross Validation\n",
    "lin_reg2_cvscores_3 = cross_val_score(lin_reg2, X, y, cv=3)\n",
    "print(f'Mean of 3 CV: {np.mean(lin_reg2_cvscores_3)}')\n",
    "\n",
    "lin_reg2_cv_scores_5 = cross_val_score(lin_reg2, X, y, cv=5)\n",
    "print(f'Mean of 5 CV: {(np.mean(lin_reg2_cv_scores_5))}')\n",
    "\n",
    "# 10 Fold\n",
    "lin_reg2_cvscores_10 = cross_val_score(lin_reg2reg2, X, y, cv=10)\n",
    "print(f'Mean of 10 CV: { np.mean(lin_reg2_cvscores_10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ridge Regression and Alpha Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "ridge_parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}\n",
    "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=5)\n",
    "ridge_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best Parameters: {ridge_regressor.best_params_} \\n\\\n",
    "      Best Score: {ridge_regressor.best_score_} \\n\\\n",
    "     Best Index: {ridge_regressor.best_index_} \\n\\\n",
    "     Scorer: {ridge_regressor.scorer_} \\n\\\n",
    "     Refit Time (Seconds): {ridge_regressor.refit_time_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso1 = Lasso(alpha=.4)\n",
    "lasso1_regressor = GridSearchCV(lasso1, parameters, scoring='neg_mean_squared_error', cv=3)\n",
    "lasso1_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best Parameters: {lasso_regressor.best_params_} \\n\\\n",
    "     Best Score: {lasso_regressor.best_score_} \\n\\\n",
    "     Best Index: {lasso_regressor.best_index_} \\n\\\n",
    "     Scorer: {lasso_regressor.scorer_} \\n\\\n",
    "     Refit Time (Seconds): {lasso_regressor.refit_time_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso2 = Lasso(alpha = .299, normalize = True)\n",
    "lasso2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best Parameters: {lasso_regressor.best_params_} \\n\\\n",
    "     Best Score: {lasso_regressor.best_score_} \\n\\\n",
    "     Best Index: {lasso_regressor.best_index_} \\n\\\n",
    "     Scorer: {lasso_regressor.scorer_} \\n\\\n",
    "     Refit Time (Seconds): {lasso_regressor.refit_time_} \\n\\\n",
    "     Score: {lasso.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "l1_space = np.linspace(0, 1, 30)\n",
    "l1_space_param_grid = {'l1_ratio': l1_space}\n",
    "\n",
    "# Instantiate the ElasticNet regressor: elastic_net\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Setup the GridSearchCV object: gm_cv\n",
    "elastic_net_gm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "elastic_net_gm_cv.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and compute metrics\n",
    "elastic_net_y_pred = gm_cv.predict(X_test)\n",
    "elastic_net_r2 = gm_cv.score(X_test, y_test)\n",
    "elastic_net_mse = mean_squared_error(y_test, elastic_net_y_pred)\n",
    "print(f'Tuned ElasticNet l1 ratio: {gm_cv.best_params_} \\n\\\n",
    "Tuned ElasticNet R squared: {elastic_net_r2} \\n\\\n",
    "Tuned ElasticNet MSE: {elastic_net_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Stacked Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_reg_estimators = [\n",
    "    ('lr', RidgeCV()),\n",
    "    ('svr', LinearSVR(random_state=42))]\n",
    "\n",
    "stacked_reg = StackingRegressor(estimators = stacked_reg_estimators,\n",
    "        final_estimator = RandomForestRegressor(n_estimators = 10,\n",
    "                                          random_state = 42))\n",
    "\n",
    "stacked_reg.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regr = RandomForestRegressor()\n",
    "rf_regr.fit(X_train, y_train)\n",
    "\n",
    "print(f'Regression Prediction: {rf_regr.predict([range(len(X.columns))])} \\n\\\n",
    "Regression Score: {rf_regr.score(X_test, y_test)} \\n\\\n",
    "Features: {rf_regr.n_features_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regr_df_y_pred = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "rf_regr_df_y_pred = rf_regr_df_y_pred.sample(25)\n",
    "\n",
    "_ = df_y_pred1.plot(kind='bar',figsize=(10,8))\n",
    "_ = plt.title('2003 No Derivatives Random Forest Regressor: Occurences Vs. Predictions')\n",
    "_ = plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "_ = plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "_ = plt.xlabel('Sample Index Numbers (25 Total)')\n",
    "_ = plt.ylabel('Grade Median Scores')\n",
    "_ = plt.xticks(rotation=80)\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_reg = GradientBoostingRegressor()\n",
    "gbr_reg.fit(X_train, y_train)\n",
    "gbr_reg.predict(X_test)\n",
    "print(f'Gradient Boosting Regressor score: {gbr_reg.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_reg_df_y_pred = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "gbr_reg_df_y_pred1 = gbr_reg_df_y_pred.sample(25)\n",
    "\n",
    "_ = gbr_reg_df_y_pred1.plot(kind='bar',figsize=(10,8))\n",
    "_ = plt.title('2003 No Derivatives Gradient Boosting Regressor: Occurences Vs. Predictions')\n",
    "_ = plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "_ = plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "_ = plt.xlabel('Sample Index Numbers (25 Total)')\n",
    "_ = plt.ylabel('Grade Median Scores')\n",
    "_ = plt.xticks(rotation=80)\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_dmatrix = xgb.DMatrix(data = X, label = y)\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.45, learning_rate = 0.4,\n",
    "                max_depth = 12, alpha = 6, n_estimators = 300)\n",
    "\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "xgb_reg_y_pred = xgb_reg.predict(X_test)\n",
    "\n",
    "xgb_reg_mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {round(xgb_reg_mse,2)} \\n\\\n",
    "RMSE: {xgb_reg_mse*(1/2.0)} \\n\\\n",
    "XGB score: {xgb_reg.score(X_test, y_test)}')\n",
    "\n",
    "# LEAPS\n",
    "print(\"MSE: %.2f\" % xgb_reg_mse)\n",
    "print(\"RMSE: %.2f\" % (xgb_reg_mse*(1/2.0)))\n",
    "xgb_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg_df_y_pred = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "xgb_reg_df_y_pred1 = xgb_reg_df_y_pred.sample(25)\n",
    "\n",
    "_ = xgb_reg_df_y_pred1.plot(kind='bar',figsize=(10,8))\n",
    "_ = plt.title('XGBoost: Occurences Vs. Predictions')\n",
    "_ = plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "_ = plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "_ = plt.xlabel('Sample Index Numbers (25 Total)')\n",
    "_ = plt.ylabel('Sales')\n",
    "_ = plt.xticks(rotation=80)\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(24, 12))\n",
    "_ = x_ax = range(len(y_test[-200:]))\n",
    "_ = plt.plot(x_ax, y_test[-200:], label=\"Occurences\")\n",
    "_ = plt.plot(x_ax, xgb_reg_y_pred[-200:], label=\"Predictions\")\n",
    "_ = plt.title('XGBoost: Occurences Vs. Predictions')\n",
    "_ = plt.xlabel('Last 200 Instances')\n",
    "_ = plt.ylabel('Sales')\n",
    "_ = plt.legend()\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "numeric_features = [\"avg_dist\", \"avg_rating_by_driver\", \"avg_rating_of_driver\", \\\n",
    "                    \"avg_surge\", \"surge_pct\", \"trips_in_first_30_days\", \"weekday_pct\"]\n",
    "numeric_transformer = [(\"scaler\", StandardScaler())]\n",
    "numeric_transformer = Pipeline(numeric_transformer)\n",
    "\n",
    "#pipeline for categorical features\n",
    "categorical_features = [\"city\", \"phone\", \"ultimate_black_user\", \"active\"]\n",
    "categorical_transformer = [(\"encoder\", OneHotEncoder())]\n",
    "categorical_transformer = Pipeline(categorical_transformer)\n",
    "\n",
    "#divernce of the pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", numeric_transformer, numeric_features), \\\n",
    "                  (\"cat\", categorical_transformer, categorical_features)])\n",
    "\n",
    "#incorporating the random forest estimator\n",
    "pipeline = Pipeline(steps=[(\"pre\", preprocessor), \\\n",
    "                           (\"ab\", AdaBoostClassifier(random_state = 42))])\n",
    "\n",
    "#grid search parameters\n",
    "params = {\"ab__n_estimators\" : [75, 100, 150],\n",
    "          \"ab__learning_rate\" : [.25, .5, .75, 1]}\n",
    "\n",
    "#fitting the pipeline to the grid search\n",
    "cv2 = GridSearchCV(pipeline, param_grid=params, cv=3)\n",
    "cv2.fit(X_train, y_train)\n",
    "\n",
    "print(cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = cv2.predict(X_test)\n",
    "\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "test_f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Model accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"Model F1 Score: {test_f1_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ada\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "fe2 = pipeline.named_steps['ab'].feature_importances_\n",
    "\n",
    "print(fe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replicating numeric_transformer of our pipeline\n",
    "num_cols = df1[numeric_features].columns\n",
    "num_cols = num_cols.tolist()\n",
    "\n",
    "#replicating categorical_transformer of our pipeline\n",
    "cat_cols = pd.get_dummies(df1[categorical_features]).columns\n",
    "cat_cols = cat_cols.tolist()\n",
    "\n",
    "#the column names are added together\n",
    "cols = num_cols + cat_cols\n",
    "\n",
    "#the column names are finally tied to our fe list\n",
    "feature_importance = zip(cols, fe2)\n",
    "feature_importance = sorted(feature_importance, key=lambda x:x[1], reverse=True)\n",
    "\n",
    "for i, j in feature_importance:\n",
    "    print(f\"Weight: {j:.3f} | Feature: {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
