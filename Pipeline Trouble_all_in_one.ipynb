{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for new packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperOpt\n",
    "## Catboost\n",
    "## Sklearn pipelines, pipeline custom transformers\n",
    "## using seaborn and bokeh for visualization\n",
    "## catboost for an algo\n",
    "## use pytest to test .py files\n",
    "## Use docker, flask, gunicorn to deploy and API\n",
    "### From there it would be deep learning with Keras and GLOVE for NLP.  You could use isolation forests or seq2seq for anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pkl = '/Users/charisameeker/Documents/Data/iowa_liquor_clean3.4.cats.pkl'\n",
    "df = pd.read_pickle(file_pkl)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(['date', 'address', 'store_name', 'item_description', 'store_subname', \\\n",
    "        'county', 'category_name', 'vendor_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.county = df.county.cat.add_categories('nan').fillna('nan')\n",
    "df.city = df.city.astype('string')\n",
    "df.zip_code = df.zip_code.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   year                 1000 non-null   int16  \n",
      " 1   month                1000 non-null   int8   \n",
      " 2   day                  1000 non-null   int8   \n",
      " 3   store_number         1000 non-null   int16  \n",
      " 4   city                 1000 non-null   string \n",
      " 5   zip_code             1000 non-null   int16  \n",
      " 6   county_number        1000 non-null   int8   \n",
      " 7   category             1000 non-null   int32  \n",
      " 8   vendor_number        1000 non-null   int16  \n",
      " 9   item_number          1000 non-null   int32  \n",
      " 10  pack                 1000 non-null   int16  \n",
      " 11  bottle_vol           1000 non-null   int64  \n",
      " 12  bottle_cost          1000 non-null   float32\n",
      " 13  state_bottle_retail  1000 non-null   float32\n",
      " 14  bottles_sold         1000 non-null   int16  \n",
      " 15  sale                 1000 non-null   float32\n",
      " 16  fd                   1000 non-null   float64\n",
      " 17  vol_sold             1000 non-null   float32\n",
      " 18  store_subnumber      1000 non-null   int16  \n",
      "dtypes: float32(4), float64(1), int16(7), int32(2), int64(1), int8(3), string(1)\n",
      "memory usage: 63.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We used the below data on Oct 29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pkl = '/Users/charisameeker/Documents/Data/iowa_liquor_clean3.5.cats.1000.pkl'\n",
    "# df.to_pickle(file_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['fd'].copy().values # fd is the result of applying boxcox on the sale column (fitted data)\n",
    "X = df.copy().drop(['sale', 'fd'], axis=1)\n",
    "X_columns = X.copy().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression() \n",
      "    model score: 0.7501\n",
      "Ridge() \n",
      "    model score: 0.7549\n",
      "Lasso() \n",
      "    model score: -0.0096\n",
      "ElasticNet() \n",
      "    model score: 0.4297\n",
      "LinearSVR() \n",
      "    model score: 0.6108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor() \n",
      "    model score: 0.9911\n",
      "GradientBoostingRegressor() \n",
      "    model score: 0.9947\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) \n",
      "    model score: 0.9948\n"
     ]
    }
   ],
   "source": [
    "regression_models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    LinearSVR(),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    xgb.XGBRegressor()\n",
    "]\n",
    "\n",
    "for regression_model in regression_models:\n",
    "    loop_pipe = make_pipeline(preprocessor, regression_model)\n",
    "    loop_pipe.fit(X_train, y_train)   \n",
    "    print(f'{regression_model} \\n\\\n",
    "    model score: {loop_pipe.score(X_test, y_test):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'month', 'day', 'store_number', 'city', 'zip_code',\n",
       "       'county_number', 'category', 'vendor_number', 'item_number', 'pack',\n",
       "       'bottle_vol', 'bottle_cost', 'state_bottle_retail', 'bottles_sold',\n",
       "       'sale', 'fd', 'vol_sold', 'store_subnumber'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestregressor__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'randomforestregressor__max_features': ['auto', 'sqrt'], 'randomforestregressor__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'randomforestregressor__min_samples_split': [2, 5, 10], 'randomforestregressor__min_samples_leaf': [1, 2, 4], 'randomforestregressor__bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "numeric_features = [\"year\", \"month\", \"day\", 'store_number', 'county_number', \\\n",
    "                    \"category\", \"vendor_number\", \"item_number\", \"pack\", 'bottle_vol', \\\n",
    "                   'bottle_cost', 'state_bottle_retail', 'bottles_sold',\\\n",
    "                   'vol_sold', 'store_subnumber']\n",
    "numeric_transformer = [(\"scaler\", StandardScaler())]\n",
    "numeric_transformer = Pipeline(numeric_transformer)\n",
    "\n",
    "#pipeline for categorical features\n",
    "categorical_features = [\"city\", \"zip_code\"]\n",
    "# store_name, item_description, store_subname\n",
    "categorical_transformer = [(\"encoder\", OneHotEncoder(handle_unknown='ignore'))]\n",
    "categorical_transformer = Pipeline(categorical_transformer)\n",
    "\n",
    "#divernce of the pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", numeric_transformer, numeric_features), \\\n",
    "                  (\"cat\", categorical_transformer, categorical_features)])\n",
    "\n",
    "#incorporating the random forest estimator\n",
    "pipeline = make_pipeline(preprocessor, RandomForestRegressor())\n",
    "\n",
    "# OLD PARAMS\n",
    "# grid search parameters\n",
    "params = {'randomforestregressor__n_estimators' : [150, 180, 210, 240],\n",
    "         'randomforestregressor__max_depth': range(3,7)}\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'randomforestregressor__n_estimators': n_estimators,\n",
    "               'randomforestregressor__max_features': max_features,\n",
    "               'randomforestregressor__max_depth': max_depth,\n",
    "               'randomforestregressor__min_samples_split': min_samples_split,\n",
    "               'randomforestregressor__min_samples_leaf': min_samples_leaf,\n",
    "               'randomforestregressor__bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "\n",
    "cv_rf = RandomizedSearchCV(pipeline, random_grid, cv=3)\n",
    "\n",
    "# 1 pipeline for data transformation\n",
    "# save as csv\n",
    "# for loop with sklearn algos, print/plot\n",
    "#   inspect default params and feature importantance\n",
    "# decide on model\n",
    "# 1 pipeline with model and gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['year',\n",
       "                                                                                'month',\n",
       "                                                                                'day',\n",
       "                                                                                'store_number',\n",
       "                                                                                'county_number',\n",
       "                                                                                'category',\n",
       "                                                                                'vendor_number',\n",
       "                                                                                'item_number',\n",
       "                                                                                'pack',\n",
       "                                                                                'bottle_vol',\n",
       "                                                                                'bottle_cost',\n",
       "                                                                                'state_bottle_retail',\n",
       "                                                                                'bottles_sold',\n",
       "                                                                                'vol_sold',\n",
       "                                                                                'store_subnumber']...\n",
       "                   param_distributions={'randomforestregressor__bootstrap': [True,\n",
       "                                                                             False],\n",
       "                                        'randomforestregressor__max_depth': [10,\n",
       "                                                                             20,\n",
       "                                                                             30,\n",
       "                                                                             40,\n",
       "                                                                             50,\n",
       "                                                                             60,\n",
       "                                                                             70,\n",
       "                                                                             80,\n",
       "                                                                             90,\n",
       "                                                                             100,\n",
       "                                                                             110,\n",
       "                                                                             None],\n",
       "                                        'randomforestregressor__max_features': ['auto',\n",
       "                                                                                'sqrt'],\n",
       "                                        'randomforestregressor__min_samples_leaf': [1,\n",
       "                                                                                    2,\n",
       "                                                                                    4],\n",
       "                                        'randomforestregressor__min_samples_split': [2,\n",
       "                                                                                     5,\n",
       "                                                                                     10],\n",
       "                                        'randomforestregressor__n_estimators': [200,\n",
       "                                                                                400,\n",
       "                                                                                600,\n",
       "                                                                                800,\n",
       "                                                                                1000,\n",
       "                                                                                1200,\n",
       "                                                                                1400,\n",
       "                                                                                1600,\n",
       "                                                                                1800,\n",
       "                                                                                2000]})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'randomforestregressor__n_estimators': 1800, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__max_depth': 110, 'randomforestregressor__bootstrap': True} \n",
      "\n",
      "Training accuracy score from tuned model: 98.84%\n"
     ]
    }
   ],
   "source": [
    "print(f'Best parameters: {cv_rf.best_params_} \\n\\n\\ # max_depth highest value 110\n",
    "Training accuracy score from tuned model: {cv_rf.best_score_*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "numeric_features = [\"year\", \"month\", \"day\", 'store_number', 'county_number', \\\n",
    "                    \"category\", \"vendor_number\", \"item_number\", \"pack\", 'bottle_vol', \\\n",
    "                   'bottle_cost', 'state_bottle_retail', 'bottles_sold',\\\n",
    "                   'vol_sold', 'store_subnumber']\n",
    "numeric_transformer = [(\"scaler\", StandardScaler())]\n",
    "numeric_transformer = Pipeline(numeric_transformer)\n",
    "\n",
    "#pipeline for categorical features\n",
    "categorical_features = [\"city\", \"zip_code\"]\n",
    "# store_name, item_description, store_subname\n",
    "categorical_transformer = [(\"encoder\", OneHotEncoder(handle_unknown='ignore'))]\n",
    "categorical_transformer = Pipeline(categorical_transformer)\n",
    "\n",
    "#divernce of the pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", numeric_transformer, numeric_features), \\\n",
    "                  (\"cat\", categorical_transformer, categorical_features)])\n",
    "\n",
    "#incorporating the random forest estimator\n",
    "pipeline = make_pipeline(preprocessor, GradientBoostingRegressor())\n",
    "\n",
    "# OLD PARAMS\n",
    "# grid search parameters\n",
    "params = {'GradientBoostingRegressor__max_depth': range(5,17,2),\n",
    "          'GradientBoostingRegressor__min_samples_split': range(200,1001,200)}\n",
    "params2 = {'GradientBoostingRegressor__max_features':range(7,20,2)}\n",
    "params3 = {'gradientboostingregressor__learning_rate': [.1, .3, .5, .7, .9],\n",
    "          'gradientboostingregressor__n_estimators': [50, 80, 100, 120, 140, 180, 250],\n",
    "          'gradientboostingregressor__subsample': [.6, .8, 1, 1.2, 1.4, 1.9],\n",
    "          'gradientboostingregressor__min_samples_split': [1, 2, 3, 4, 6]}\n",
    "\n",
    "cv_gb = RandomizedSearchCV(pipeline, params3, cv=3)\n",
    "\n",
    "# 1 pipeline for data transformation\n",
    "# save as csv\n",
    "# for loop with sklearn algos, print/plot\n",
    "#   inspect default params and feature importantance\n",
    "# decide on model\n",
    "# 1 pipeline with model and gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 251, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but \"\n",
      "ValueError: subsample must be in (0,1] but was 1.4\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 251, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but \"\n",
      "ValueError: subsample must be in (0,1] but was 1.4\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 251, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but \"\n",
      "ValueError: subsample must be in (0,1] but was 1.4\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 251, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but \"\n",
      "ValueError: subsample must be in (0,1] but was 1.4\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 251, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but \"\n",
      "ValueError: subsample must be in (0,1] but was 1.4\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 251, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but \"\n",
      "ValueError: subsample must be in (0,1] but was 1.4\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 251, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but \"\n",
      "ValueError: subsample must be in (0,1] but was 1.4\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 251, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but \"\n",
      "ValueError: subsample must be in (0,1] but was 1.4\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 251, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but \"\n",
      "ValueError: subsample must be in (0,1] but was 1.4\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['year',\n",
       "                                                                                'month',\n",
       "                                                                                'day',\n",
       "                                                                                'store_number',\n",
       "                                                                                'county_number',\n",
       "                                                                                'category',\n",
       "                                                                                'vendor_number',\n",
       "                                                                                'item_number',\n",
       "                                                                                'pack',\n",
       "                                                                                'bottle_vol',\n",
       "                                                                                'bottle_cost',\n",
       "                                                                                'state_bottle_retail',\n",
       "                                                                                'bottles_sold',\n",
       "                                                                                'vol_sold',\n",
       "                                                                                'store_subnumber']...\n",
       "                                                                                'zip_code'])])),\n",
       "                                             ('gradientboostingregressor',\n",
       "                                              GradientBoostingRegressor())]),\n",
       "                   param_distributions={'gradientboostingregressor__learning_rate': [0.1,\n",
       "                                                                                     0.3,\n",
       "                                                                                     0.5,\n",
       "                                                                                     0.7,\n",
       "                                                                                     0.9],\n",
       "                                        'gradientboostingregressor__min_samples_split': [1,\n",
       "                                                                                         2,\n",
       "                                                                                         3,\n",
       "                                                                                         4,\n",
       "                                                                                         6],\n",
       "                                        'gradientboostingregressor__n_estimators': [50,\n",
       "                                                                                    80,\n",
       "                                                                                    100,\n",
       "                                                                                    120,\n",
       "                                                                                    140,\n",
       "                                                                                    180,\n",
       "                                                                                    250],\n",
       "                                        'gradientboostingregressor__subsample': [0.6,\n",
       "                                                                                 0.8,\n",
       "                                                                                 1,\n",
       "                                                                                 1.2,\n",
       "                                                                                 1.4,\n",
       "                                                                                 1.9]})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'gradientboostingregressor__subsample': 0.6, 'gradientboostingregressor__n_estimators': 140, 'gradientboostingregressor__min_samples_split': 2, 'gradientboostingregressor__learning_rate': 0.1} \n",
      "\n",
      "Training accuracy score from tuned model: 99.66%\n"
     ]
    }
   ],
   "source": [
    "print(f'Best parameters: {cv_gb.best_params_} \\n\\n\\\n",
    "Training accuracy score from tuned model: {cv_gb.best_score_*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameter Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cv',\n",
       " 'error_score',\n",
       " 'estimator',\n",
       " 'estimator__columntransformer',\n",
       " 'estimator__columntransformer__cat',\n",
       " 'estimator__columntransformer__cat__encoder',\n",
       " 'estimator__columntransformer__cat__encoder__categories',\n",
       " 'estimator__columntransformer__cat__encoder__drop',\n",
       " 'estimator__columntransformer__cat__encoder__dtype',\n",
       " 'estimator__columntransformer__cat__encoder__handle_unknown',\n",
       " 'estimator__columntransformer__cat__encoder__sparse',\n",
       " 'estimator__columntransformer__cat__memory',\n",
       " 'estimator__columntransformer__cat__steps',\n",
       " 'estimator__columntransformer__cat__verbose',\n",
       " 'estimator__columntransformer__n_jobs',\n",
       " 'estimator__columntransformer__num',\n",
       " 'estimator__columntransformer__num__memory',\n",
       " 'estimator__columntransformer__num__scaler',\n",
       " 'estimator__columntransformer__num__scaler__copy',\n",
       " 'estimator__columntransformer__num__scaler__with_mean',\n",
       " 'estimator__columntransformer__num__scaler__with_std',\n",
       " 'estimator__columntransformer__num__steps',\n",
       " 'estimator__columntransformer__num__verbose',\n",
       " 'estimator__columntransformer__remainder',\n",
       " 'estimator__columntransformer__sparse_threshold',\n",
       " 'estimator__columntransformer__transformer_weights',\n",
       " 'estimator__columntransformer__transformers',\n",
       " 'estimator__columntransformer__verbose',\n",
       " 'estimator__gradientboostingregressor',\n",
       " 'estimator__gradientboostingregressor__alpha',\n",
       " 'estimator__gradientboostingregressor__ccp_alpha',\n",
       " 'estimator__gradientboostingregressor__criterion',\n",
       " 'estimator__gradientboostingregressor__init',\n",
       " 'estimator__gradientboostingregressor__learning_rate',\n",
       " 'estimator__gradientboostingregressor__loss',\n",
       " 'estimator__gradientboostingregressor__max_depth',\n",
       " 'estimator__gradientboostingregressor__max_features',\n",
       " 'estimator__gradientboostingregressor__max_leaf_nodes',\n",
       " 'estimator__gradientboostingregressor__min_impurity_decrease',\n",
       " 'estimator__gradientboostingregressor__min_impurity_split',\n",
       " 'estimator__gradientboostingregressor__min_samples_leaf',\n",
       " 'estimator__gradientboostingregressor__min_samples_split',\n",
       " 'estimator__gradientboostingregressor__min_weight_fraction_leaf',\n",
       " 'estimator__gradientboostingregressor__n_estimators',\n",
       " 'estimator__gradientboostingregressor__n_iter_no_change',\n",
       " 'estimator__gradientboostingregressor__presort',\n",
       " 'estimator__gradientboostingregressor__random_state',\n",
       " 'estimator__gradientboostingregressor__subsample',\n",
       " 'estimator__gradientboostingregressor__tol',\n",
       " 'estimator__gradientboostingregressor__validation_fraction',\n",
       " 'estimator__gradientboostingregressor__verbose',\n",
       " 'estimator__gradientboostingregressor__warm_start',\n",
       " 'estimator__memory',\n",
       " 'estimator__steps',\n",
       " 'estimator__verbose',\n",
       " 'iid',\n",
       " 'n_iter',\n",
       " 'n_jobs',\n",
       " 'param_distributions',\n",
       " 'pre_dispatch',\n",
       " 'random_state',\n",
       " 'refit',\n",
       " 'return_train_score',\n",
       " 'scoring',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cv_gb.get_params().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "numeric_features = [\"year\", \"month\", \"day\", 'store_number', 'county_number', \\\n",
    "                    \"category\", \"vendor_number\", \"item_number\", \"pack\", 'bottle_vol', \\\n",
    "                   'bottle_cost', 'state_bottle_retail', 'bottles_sold',\\\n",
    "                   'vol_sold', 'store_subnumber']\n",
    "numeric_transformer = [(\"scaler\", StandardScaler())]\n",
    "numeric_transformer = Pipeline(numeric_transformer)\n",
    "\n",
    "#pipeline for categorical features\n",
    "categorical_features = [\"city\", \"zip_code\"]\n",
    "# store_name, item_description, store_subname\n",
    "categorical_transformer = [(\"encoder\", OneHotEncoder(handle_unknown='ignore'))]\n",
    "categorical_transformer = Pipeline(categorical_transformer)\n",
    "\n",
    "#divernce of the pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", numeric_transformer, numeric_features), \\\n",
    "                  (\"cat\", categorical_transformer, categorical_features)])\n",
    "\n",
    "#incorporating the random forest estimator\n",
    "pipeline = make_pipeline(preprocessor, xgb.XGBRegressor())\n",
    "\n",
    "# parameters\n",
    "parameters = {'xgbregressor__nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'xgbregressor__objective':['reg:linear'],\n",
    "              'xgbregressor__learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'xgbregressor__max_depth': [5, 6, 7],\n",
    "              'xgbregressor__min_child_weight': [4],\n",
    "              'xgbregressor__silent': [1],\n",
    "              'xgbregressor__subsample': [0.7],\n",
    "              'xgbregressor__colsample_bytree': [0.7],\n",
    "              'xgbregressor__n_estimators': [500]}\n",
    "\n",
    "# 1 pipeline for data transformation\n",
    "# save as csv\n",
    "# for loop with sklearn algos, print/plot\n",
    "#   inspect default params and feature importantance\n",
    "# decide on model\n",
    "# 1 pipeline with model and gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_xgb = RandomizedSearchCV(pipeline, parameters, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:278: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:12:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[17:12:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost_1598185652448/work/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['year',\n",
       "                                                                                'month',\n",
       "                                                                                'day',\n",
       "                                                                                'store_number',\n",
       "                                                                                'county_number',\n",
       "                                                                                'category',\n",
       "                                                                                'vendor_number',\n",
       "                                                                                'item_number',\n",
       "                                                                                'pack',\n",
       "                                                                                'bottle_vol',\n",
       "                                                                                'bottle_cost',\n",
       "                                                                                'state_bottle_retail',\n",
       "                                                                                'bottles_sold',\n",
       "                                                                                'vol_sold',\n",
       "                                                                                'store_subnumber']...\n",
       "                                                           verbosity=None))]),\n",
       "                   param_distributions={'xgbregressor__colsample_bytree': [0.7],\n",
       "                                        'xgbregressor__learning_rate': [0.03,\n",
       "                                                                        0.05,\n",
       "                                                                        0.07],\n",
       "                                        'xgbregressor__max_depth': [5, 6, 7],\n",
       "                                        'xgbregressor__min_child_weight': [4],\n",
       "                                        'xgbregressor__n_estimators': [500],\n",
       "                                        'xgbregressor__nthread': [4],\n",
       "                                        'xgbregressor__objective': ['reg:linear'],\n",
       "                                        'xgbregressor__silent': [1],\n",
       "                                        'xgbregressor__subsample': [0.7]})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'xgbregressor__subsample': 0.7, 'xgbregressor__silent': 1, 'xgbregressor__objective': 'reg:linear', 'xgbregressor__nthread': 4, 'xgbregressor__n_estimators': 500, 'xgbregressor__min_child_weight': 4, 'xgbregressor__max_depth': 5, 'xgbregressor__learning_rate': 0.07, 'xgbregressor__colsample_bytree': 0.7} \n",
      "\n",
      "Training accuracy score from tuned model: 99.61%\n"
     ]
    }
   ],
   "source": [
    "print(f'Best parameters: {cv_xgb.best_params_} \\n\\n\\\n",
    "Training accuracy score from tuned model: {cv_xgb.best_score_*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameter Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cv',\n",
       " 'error_score',\n",
       " 'estimator',\n",
       " 'estimator__columntransformer',\n",
       " 'estimator__columntransformer__cat',\n",
       " 'estimator__columntransformer__cat__encoder',\n",
       " 'estimator__columntransformer__cat__encoder__categories',\n",
       " 'estimator__columntransformer__cat__encoder__drop',\n",
       " 'estimator__columntransformer__cat__encoder__dtype',\n",
       " 'estimator__columntransformer__cat__encoder__handle_unknown',\n",
       " 'estimator__columntransformer__cat__encoder__sparse',\n",
       " 'estimator__columntransformer__cat__memory',\n",
       " 'estimator__columntransformer__cat__steps',\n",
       " 'estimator__columntransformer__cat__verbose',\n",
       " 'estimator__columntransformer__n_jobs',\n",
       " 'estimator__columntransformer__num',\n",
       " 'estimator__columntransformer__num__memory',\n",
       " 'estimator__columntransformer__num__scaler',\n",
       " 'estimator__columntransformer__num__scaler__copy',\n",
       " 'estimator__columntransformer__num__scaler__with_mean',\n",
       " 'estimator__columntransformer__num__scaler__with_std',\n",
       " 'estimator__columntransformer__num__steps',\n",
       " 'estimator__columntransformer__num__verbose',\n",
       " 'estimator__columntransformer__remainder',\n",
       " 'estimator__columntransformer__sparse_threshold',\n",
       " 'estimator__columntransformer__transformer_weights',\n",
       " 'estimator__columntransformer__transformers',\n",
       " 'estimator__columntransformer__verbose',\n",
       " 'estimator__memory',\n",
       " 'estimator__steps',\n",
       " 'estimator__verbose',\n",
       " 'estimator__xgbregressor',\n",
       " 'estimator__xgbregressor__base_score',\n",
       " 'estimator__xgbregressor__booster',\n",
       " 'estimator__xgbregressor__colsample_bylevel',\n",
       " 'estimator__xgbregressor__colsample_bynode',\n",
       " 'estimator__xgbregressor__colsample_bytree',\n",
       " 'estimator__xgbregressor__gamma',\n",
       " 'estimator__xgbregressor__gpu_id',\n",
       " 'estimator__xgbregressor__importance_type',\n",
       " 'estimator__xgbregressor__interaction_constraints',\n",
       " 'estimator__xgbregressor__learning_rate',\n",
       " 'estimator__xgbregressor__max_delta_step',\n",
       " 'estimator__xgbregressor__max_depth',\n",
       " 'estimator__xgbregressor__min_child_weight',\n",
       " 'estimator__xgbregressor__missing',\n",
       " 'estimator__xgbregressor__monotone_constraints',\n",
       " 'estimator__xgbregressor__n_estimators',\n",
       " 'estimator__xgbregressor__n_jobs',\n",
       " 'estimator__xgbregressor__num_parallel_tree',\n",
       " 'estimator__xgbregressor__objective',\n",
       " 'estimator__xgbregressor__random_state',\n",
       " 'estimator__xgbregressor__reg_alpha',\n",
       " 'estimator__xgbregressor__reg_lambda',\n",
       " 'estimator__xgbregressor__scale_pos_weight',\n",
       " 'estimator__xgbregressor__subsample',\n",
       " 'estimator__xgbregressor__tree_method',\n",
       " 'estimator__xgbregressor__validate_parameters',\n",
       " 'estimator__xgbregressor__verbosity',\n",
       " 'iid',\n",
       " 'n_iter',\n",
       " 'n_jobs',\n",
       " 'param_distributions',\n",
       " 'pre_dispatch',\n",
       " 'random_state',\n",
       " 'refit',\n",
       " 'return_train_score',\n",
       " 'scoring',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cv_xgb.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import any_regressor\n",
    "from hpsklearn import any_preprocessing\n",
    "from hyperopt import tpe\n",
    "\n",
    "estim = HyperoptEstimator(classifier=any_regressor('my_clf'),\n",
    "preprocessing=any_preprocessing('my_pre'),\n",
    "algo=tpe.suggest,\n",
    "max_evals=3,\n",
    "trial_timeout=120)\n",
    "\n",
    "estim.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "print(f'Score: {estim.score(X_test, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
